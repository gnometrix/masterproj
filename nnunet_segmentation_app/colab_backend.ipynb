{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "EvWoFtTNQGiZ",
        "outputId": "2390b181-690e-4034-9351-334c82d702d3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: flask in /usr/local/lib/python3.11/dist-packages (3.1.0)\n",
            "Collecting pyngrok\n",
            "  Downloading pyngrok-7.2.3-py3-none-any.whl.metadata (8.7 kB)\n",
            "Requirement already satisfied: Werkzeug>=3.1 in /usr/local/lib/python3.11/dist-packages (from flask) (3.1.3)\n",
            "Requirement already satisfied: Jinja2>=3.1.2 in /usr/local/lib/python3.11/dist-packages (from flask) (3.1.5)\n",
            "Requirement already satisfied: itsdangerous>=2.2 in /usr/local/lib/python3.11/dist-packages (from flask) (2.2.0)\n",
            "Requirement already satisfied: click>=8.1.3 in /usr/local/lib/python3.11/dist-packages (from flask) (8.1.8)\n",
            "Requirement already satisfied: blinker>=1.9 in /usr/local/lib/python3.11/dist-packages (from flask) (1.9.0)\n",
            "Requirement already satisfied: PyYAML>=5.1 in /usr/local/lib/python3.11/dist-packages (from pyngrok) (6.0.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from Jinja2>=3.1.2->flask) (3.0.2)\n",
            "Downloading pyngrok-7.2.3-py3-none-any.whl (23 kB)\n",
            "Installing collected packages: pyngrok\n",
            "Successfully installed pyngrok-7.2.3\n",
            "Collecting nnunetv2\n",
            "  Downloading nnunetv2-2.6.0.tar.gz (206 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m206.3/206.3 kB\u001b[0m \u001b[31m14.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: torch>=2.1.2 in /usr/local/lib/python3.11/dist-packages (from nnunetv2) (2.5.1+cu124)\n",
            "Collecting acvl-utils<0.3,>=0.2.3 (from nnunetv2)\n",
            "  Downloading acvl_utils-0.2.5.tar.gz (29 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting dynamic-network-architectures<0.4,>=0.3.1 (from nnunetv2)\n",
            "  Downloading dynamic_network_architectures-0.3.1.tar.gz (20 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from nnunetv2) (4.67.1)\n",
            "Collecting dicom2nifti (from nnunetv2)\n",
            "  Downloading dicom2nifti-2.5.1-py3-none-any.whl.metadata (1.3 kB)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from nnunetv2) (1.13.1)\n",
            "Collecting batchgenerators>=0.25.1 (from nnunetv2)\n",
            "  Downloading batchgenerators-0.25.1.tar.gz (76 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.0/77.0 kB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy>=1.24 in /usr/local/lib/python3.11/dist-packages (from nnunetv2) (1.26.4)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (from nnunetv2) (1.6.1)\n",
            "Requirement already satisfied: scikit-image>=0.19.3 in /usr/local/lib/python3.11/dist-packages (from nnunetv2) (0.25.2)\n",
            "Collecting SimpleITK>=2.2.1 (from nnunetv2)\n",
            "  Downloading SimpleITK-2.4.1-cp311-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.9 kB)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from nnunetv2) (2.2.2)\n",
            "Requirement already satisfied: graphviz in /usr/local/lib/python3.11/dist-packages (from nnunetv2) (0.20.3)\n",
            "Requirement already satisfied: tifffile in /usr/local/lib/python3.11/dist-packages (from nnunetv2) (2025.2.18)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from nnunetv2) (2.32.3)\n",
            "Requirement already satisfied: nibabel in /usr/local/lib/python3.11/dist-packages (from nnunetv2) (5.3.2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (from nnunetv2) (3.10.0)\n",
            "Requirement already satisfied: seaborn in /usr/local/lib/python3.11/dist-packages (from nnunetv2) (0.13.2)\n",
            "Collecting imagecodecs (from nnunetv2)\n",
            "  Downloading imagecodecs-2024.12.30-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (19 kB)\n",
            "Collecting yacs (from nnunetv2)\n",
            "  Downloading yacs-0.1.8-py3-none-any.whl.metadata (639 bytes)\n",
            "Collecting batchgeneratorsv2>=0.2 (from nnunetv2)\n",
            "  Downloading batchgeneratorsv2-0.2.3.tar.gz (35 kB)\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: einops in /usr/local/lib/python3.11/dist-packages (from nnunetv2) (0.8.1)\n",
            "Requirement already satisfied: blosc2>=3.0.0b1 in /usr/local/lib/python3.11/dist-packages (from nnunetv2) (3.1.1)\n",
            "Collecting connected-components-3d (from acvl-utils<0.3,>=0.2.3->nnunetv2)\n",
            "  Downloading connected_components_3d-3.23.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (32 kB)\n",
            "Requirement already satisfied: pillow>=7.1.2 in /usr/local/lib/python3.11/dist-packages (from batchgenerators>=0.25.1->nnunetv2) (11.1.0)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.11/dist-packages (from batchgenerators>=0.25.1->nnunetv2) (1.0.0)\n",
            "Collecting unittest2 (from batchgenerators>=0.25.1->nnunetv2)\n",
            "  Downloading unittest2-1.1.0-py2.py3-none-any.whl.metadata (15 kB)\n",
            "Requirement already satisfied: threadpoolctl in /usr/local/lib/python3.11/dist-packages (from batchgenerators>=0.25.1->nnunetv2) (3.5.0)\n",
            "Collecting fft-conv-pytorch (from batchgeneratorsv2>=0.2->nnunetv2)\n",
            "  Downloading fft_conv_pytorch-1.2.0-py3-none-any.whl.metadata (2.8 kB)\n",
            "Requirement already satisfied: ndindex in /usr/local/lib/python3.11/dist-packages (from blosc2>=3.0.0b1->nnunetv2) (1.9.2)\n",
            "Requirement already satisfied: msgpack in /usr/local/lib/python3.11/dist-packages (from blosc2>=3.0.0b1->nnunetv2) (1.1.0)\n",
            "Requirement already satisfied: numexpr in /usr/local/lib/python3.11/dist-packages (from blosc2>=3.0.0b1->nnunetv2) (2.10.2)\n",
            "Requirement already satisfied: py-cpuinfo in /usr/local/lib/python3.11/dist-packages (from blosc2>=3.0.0b1->nnunetv2) (9.0.0)\n",
            "Requirement already satisfied: httpx in /usr/local/lib/python3.11/dist-packages (from blosc2>=3.0.0b1->nnunetv2) (0.28.1)\n",
            "Requirement already satisfied: platformdirs in /usr/local/lib/python3.11/dist-packages (from blosc2>=3.0.0b1->nnunetv2) (4.3.6)\n",
            "Requirement already satisfied: networkx>=3.0 in /usr/local/lib/python3.11/dist-packages (from scikit-image>=0.19.3->nnunetv2) (3.4.2)\n",
            "Requirement already satisfied: imageio!=2.35.0,>=2.33 in /usr/local/lib/python3.11/dist-packages (from scikit-image>=0.19.3->nnunetv2) (2.37.0)\n",
            "Requirement already satisfied: packaging>=21 in /usr/local/lib/python3.11/dist-packages (from scikit-image>=0.19.3->nnunetv2) (24.2)\n",
            "Requirement already satisfied: lazy-loader>=0.4 in /usr/local/lib/python3.11/dist-packages (from scikit-image>=0.19.3->nnunetv2) (0.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.2->nnunetv2) (3.17.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.2->nnunetv2) (4.12.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.2->nnunetv2) (3.1.5)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.2->nnunetv2) (2024.10.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch>=2.1.2->nnunetv2)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch>=2.1.2->nnunetv2)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch>=2.1.2->nnunetv2)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=2.1.2->nnunetv2)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch>=2.1.2->nnunetv2)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch>=2.1.2->nnunetv2)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch>=2.1.2->nnunetv2)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch>=2.1.2->nnunetv2)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch>=2.1.2->nnunetv2)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.2->nnunetv2) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.2->nnunetv2) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch>=2.1.2->nnunetv2)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.2->nnunetv2) (3.1.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.2->nnunetv2) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=2.1.2->nnunetv2) (1.3.0)\n",
            "Collecting pydicom>=2.2.0 (from dicom2nifti->nnunetv2)\n",
            "  Downloading pydicom-3.0.1-py3-none-any.whl.metadata (9.4 kB)\n",
            "Collecting python-gdcm (from dicom2nifti->nnunetv2)\n",
            "  Downloading python_gdcm-3.0.24.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.7 kB)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->nnunetv2) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib->nnunetv2) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->nnunetv2) (4.56.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->nnunetv2) (1.4.8)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->nnunetv2) (3.2.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib->nnunetv2) (2.8.2)\n",
            "Requirement already satisfied: importlib-resources>=5.12 in /usr/local/lib/python3.11/dist-packages (from nibabel->nnunetv2) (6.5.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->nnunetv2) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->nnunetv2) (2025.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->nnunetv2) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->nnunetv2) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->nnunetv2) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->nnunetv2) (2025.1.31)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->nnunetv2) (1.4.2)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.11/dist-packages (from yacs->nnunetv2) (6.0.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib->nnunetv2) (1.17.0)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx->blosc2>=3.0.0b1->nnunetv2) (3.7.1)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx->blosc2>=3.0.0b1->nnunetv2) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx->blosc2>=3.0.0b1->nnunetv2) (0.14.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=2.1.2->nnunetv2) (3.0.2)\n",
            "Collecting argparse (from unittest2->batchgenerators>=0.25.1->nnunetv2)\n",
            "  Downloading argparse-1.4.0-py2.py3-none-any.whl.metadata (2.8 kB)\n",
            "Collecting traceback2 (from unittest2->batchgenerators>=0.25.1->nnunetv2)\n",
            "  Downloading traceback2-1.4.0-py2.py3-none-any.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx->blosc2>=3.0.0b1->nnunetv2) (1.3.1)\n",
            "Collecting linecache2 (from traceback2->unittest2->batchgenerators>=0.25.1->nnunetv2)\n",
            "  Downloading linecache2-1.0.0-py2.py3-none-any.whl.metadata (1000 bytes)\n",
            "Downloading SimpleITK-2.4.1-cp311-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (52.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m52.3/52.3 MB\u001b[0m \u001b[31m19.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m112.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m87.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m57.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m1.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m12.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m93.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dicom2nifti-2.5.1-py3-none-any.whl (43 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.6/43.6 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading imagecodecs-2024.12.30-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (45.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.5/45.5 MB\u001b[0m \u001b[31m12.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading yacs-0.1.8-py3-none-any.whl (14 kB)\n",
            "Downloading pydicom-3.0.1-py3-none-any.whl (2.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m87.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading connected_components_3d-3.23.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.3/4.3 MB\u001b[0m \u001b[31m76.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading fft_conv_pytorch-1.2.0-py3-none-any.whl (6.8 kB)\n",
            "Downloading python_gdcm-3.0.24.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.1/13.1 MB\u001b[0m \u001b[31m105.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading unittest2-1.1.0-py2.py3-none-any.whl (96 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m96.4/96.4 kB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading argparse-1.4.0-py2.py3-none-any.whl (23 kB)\n",
            "Downloading traceback2-1.4.0-py2.py3-none-any.whl (16 kB)\n",
            "Downloading linecache2-1.0.0-py2.py3-none-any.whl (12 kB)\n",
            "Building wheels for collected packages: nnunetv2, acvl-utils, batchgenerators, batchgeneratorsv2, dynamic-network-architectures\n",
            "  Building wheel for nnunetv2 (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for nnunetv2: filename=nnunetv2-2.6.0-py3-none-any.whl size=276978 sha256=23d3cd8cc92ff48d2f848345a4e04952bdac8baf25706e5a50c7fb7ee60b9fa6\n",
            "  Stored in directory: /root/.cache/pip/wheels/3d/0d/bb/f932cb0032d1aacc2f336de421448313d147db8eed671096e9\n",
            "  Building wheel for acvl-utils (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for acvl-utils: filename=acvl_utils-0.2.5-py3-none-any.whl size=27214 sha256=634f57771062467a26fbef5268425d60b7781beac736dcacdc4bf27097f9a5d5\n",
            "  Stored in directory: /root/.cache/pip/wheels/3f/8c/10/dcba79e0b2d1d463605233cec1fc6cfad47af5230b8985e464\n",
            "  Building wheel for batchgenerators (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for batchgenerators: filename=batchgenerators-0.25.1-py3-none-any.whl size=93088 sha256=40a79069637d6aa17730b1b06b90144bfc279c722b9169feeb76021b0c95109d\n",
            "  Stored in directory: /root/.cache/pip/wheels/56/11/c7/fadca30e054c602093ffe36ba8a2f0a87dd2f86ac75191d3ed\n",
            "  Building wheel for batchgeneratorsv2 (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for batchgeneratorsv2: filename=batchgeneratorsv2-0.2.3-py3-none-any.whl size=47526 sha256=104acc7f713860b8096b0206187ae5ed68c24fca92ebf6a09b5b9de0c1611bb8\n",
            "  Stored in directory: /root/.cache/pip/wheels/1f/68/57/3a0eceb67b9c1b630df16113639b66a843dfd6686a4ed5ae1d\n",
            "  Building wheel for dynamic-network-architectures (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for dynamic-network-architectures: filename=dynamic_network_architectures-0.3.1-py3-none-any.whl size=30046 sha256=71056fecb46d7c1ff59724b598c9338d0ba96f4f54335d2bf3470bc3b8c71655\n",
            "  Stored in directory: /root/.cache/pip/wheels/d9/8f/23/133ba252665b6f93abdbb294b323cc8fec041be83e4d22b701\n",
            "Successfully built nnunetv2 acvl-utils batchgenerators batchgeneratorsv2 dynamic-network-architectures\n",
            "Installing collected packages: SimpleITK, linecache2, argparse, yacs, traceback2, python-gdcm, pydicom, nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, imagecodecs, connected-components-3d, unittest2, nvidia-cusparse-cu12, nvidia-cudnn-cu12, dicom2nifti, nvidia-cusolver-cu12, batchgenerators, fft-conv-pytorch, dynamic-network-architectures, acvl-utils, batchgeneratorsv2, nnunetv2\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed SimpleITK-2.4.1 acvl-utils-0.2.5 argparse-1.4.0 batchgenerators-0.25.1 batchgeneratorsv2-0.2.3 connected-components-3d-3.23.0 dicom2nifti-2.5.1 dynamic-network-architectures-0.3.1 fft-conv-pytorch-1.2.0 imagecodecs-2024.12.30 linecache2-1.0.0 nnunetv2-2.6.0 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 pydicom-3.0.1 python-gdcm-3.0.24.1 traceback2-1.4.0 unittest2-1.1.0 yacs-0.1.8\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "argparse"
                ]
              },
              "id": "c3443e76f59249cb91c9ce0f3fc1e566"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: dicom2nifti in /usr/local/lib/python3.11/dist-packages (2.5.1)\n",
            "Requirement already satisfied: pydicom in /usr/local/lib/python3.11/dist-packages (3.0.1)\n",
            "Requirement already satisfied: nibabel in /usr/local/lib/python3.11/dist-packages (from dicom2nifti) (5.3.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from dicom2nifti) (1.26.4)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from dicom2nifti) (1.13.1)\n",
            "Requirement already satisfied: python-gdcm in /usr/local/lib/python3.11/dist-packages (from dicom2nifti) (3.0.24.1)\n",
            "Requirement already satisfied: importlib-resources>=5.12 in /usr/local/lib/python3.11/dist-packages (from nibabel->dicom2nifti) (6.5.2)\n",
            "Requirement already satisfied: packaging>=20 in /usr/local/lib/python3.11/dist-packages (from nibabel->dicom2nifti) (24.2)\n",
            "Requirement already satisfied: typing-extensions>=4.6 in /usr/local/lib/python3.11/dist-packages (from nibabel->dicom2nifti) (4.12.2)\n",
            "Get:1 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease [3,632 B]\n",
            "Get:2 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease [1,581 B]\n",
            "Get:3 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ Packages [68.9 kB]\n",
            "Get:4 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  Packages [1,321 kB]\n",
            "Hit:5 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
            "Get:6 http://archive.ubuntu.com/ubuntu jammy-updates InRelease [128 kB]\n",
            "Get:7 http://security.ubuntu.com/ubuntu jammy-security InRelease [129 kB]\n",
            "Hit:8 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n",
            "Get:9 https://r2u.stat.illinois.edu/ubuntu jammy InRelease [6,555 B]\n",
            "Hit:10 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n",
            "Hit:11 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n",
            "Get:12 https://r2u.stat.illinois.edu/ubuntu jammy/main all Packages [8,708 kB]\n",
            "Get:13 http://archive.ubuntu.com/ubuntu jammy-backports InRelease [127 kB]\n",
            "Get:14 http://security.ubuntu.com/ubuntu jammy-security/universe amd64 Packages [1,235 kB]\n",
            "Get:15 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 Packages [2,956 kB]\n",
            "Get:16 http://security.ubuntu.com/ubuntu jammy-security/restricted amd64 Packages [3,688 kB]\n",
            "Get:17 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 Packages [1,533 kB]\n",
            "Get:18 http://archive.ubuntu.com/ubuntu jammy-updates/restricted amd64 Packages [3,830 kB]\n",
            "Get:19 http://security.ubuntu.com/ubuntu jammy-security/main amd64 Packages [2,649 kB]\n",
            "Get:20 https://r2u.stat.illinois.edu/ubuntu jammy/main amd64 Packages [2,664 kB]\n",
            "Fetched 29.0 MB in 4s (7,173 kB/s)\n",
            "Reading package lists... Done\n",
            "W: Skipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "The following additional packages will be installed:\n",
            "  libyaml-cpp0.7\n",
            "The following NEW packages will be installed:\n",
            "  dcm2niix libyaml-cpp0.7\n",
            "0 upgraded, 2 newly installed, 0 to remove and 36 not upgraded.\n",
            "Need to get 354 kB of archives.\n",
            "After this operation, 1,231 kB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu jammy/main amd64 libyaml-cpp0.7 amd64 0.7.0+dfsg-8build1 [97.7 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu jammy/universe amd64 dcm2niix amd64 1.0.20211006-1build1 [256 kB]\n",
            "Fetched 354 kB in 2s (231 kB/s)\n",
            "Selecting previously unselected package libyaml-cpp0.7:amd64.\n",
            "(Reading database ... 124947 files and directories currently installed.)\n",
            "Preparing to unpack .../libyaml-cpp0.7_0.7.0+dfsg-8build1_amd64.deb ...\n",
            "Unpacking libyaml-cpp0.7:amd64 (0.7.0+dfsg-8build1) ...\n",
            "Selecting previously unselected package dcm2niix.\n",
            "Preparing to unpack .../dcm2niix_1.0.20211006-1build1_amd64.deb ...\n",
            "Unpacking dcm2niix (1.0.20211006-1build1) ...\n",
            "Setting up libyaml-cpp0.7:amd64 (0.7.0+dfsg-8build1) ...\n",
            "Setting up dcm2niix (1.0.20211006-1build1) ...\n",
            "Processing triggers for man-db (2.10.2-1) ...\n",
            "Processing triggers for libc-bin (2.35-0ubuntu3.8) ...\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbb.so.12 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libhwloc.so.15 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libumf.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_0.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_5.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc.so.2 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc_proxy.so.2 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtcm.so.1 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_adapter_opencl.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtcm_debug.so.1 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_adapter_level_zero.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_loader.so.0 is not a symbolic link\n",
            "\n",
            "Requirement already satisfied: nibabel in /usr/local/lib/python3.11/dist-packages (5.3.2)\n",
            "Requirement already satisfied: importlib-resources>=5.12 in /usr/local/lib/python3.11/dist-packages (from nibabel) (6.5.2)\n",
            "Requirement already satisfied: numpy>=1.22 in /usr/local/lib/python3.11/dist-packages (from nibabel) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20 in /usr/local/lib/python3.11/dist-packages (from nibabel) (24.2)\n",
            "Requirement already satisfied: typing-extensions>=4.6 in /usr/local/lib/python3.11/dist-packages (from nibabel) (4.12.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install flask pyngrok\n",
        "!pip install nnunetv2\n",
        "!pip install dicom2nifti pydicom\n",
        "!apt-get update\n",
        "!apt-get install -y dcm2niix\n",
        "!pip install nibabel"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "import os\n",
        "\n",
        "# Mount Google Drive\n",
        "drive.mount('/content/drive', force_remount=True)\n",
        "\n",
        "# Define nnUNet base directory\n",
        "BASE_DIR = \"/content/drive/MyDrive/nnUNet_data\"\n",
        "\n",
        "# Define required nnUNet paths\n",
        "os.environ[\"nnUNet_raw\"] = os.path.join(BASE_DIR, \"nnUNet_raw\")\n",
        "os.environ[\"nnUNet_preprocessed\"] = os.path.join(BASE_DIR, \"nnUNet_preprocessed\")\n",
        "os.environ[\"nnUNet_results\"] = os.path.join(BASE_DIR, \"nnUNet_results\")\n",
        "\n",
        "# Verify paths\n",
        "print(\"✅ nnUNet Paths Set:\")\n",
        "print(f\"nnUNet_raw: {os.environ['nnUNet_raw']}\")\n",
        "print(f\"nnUNet_preprocessed: {os.environ['nnUNet_preprocessed']}\")\n",
        "print(f\"nnUNet_results: {os.environ['nnUNet_results']}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e98Ao0_8QPq8",
        "outputId": "3cbf8518-64d6-43a0-a41c-83a19d40bc0b"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "✅ nnUNet Paths Set:\n",
            "nnUNet_raw: /content/drive/MyDrive/nnUNet_data/nnUNet_raw\n",
            "nnUNet_preprocessed: /content/drive/MyDrive/nnUNet_data/nnUNet_preprocessed\n",
            "nnUNet_results: /content/drive/MyDrive/nnUNet_data/nnUNet_results\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import glob\n",
        "import shutil\n",
        "import subprocess\n",
        "import tempfile\n",
        "import zipfile\n",
        "from flask import Flask, request, jsonify, send_from_directory\n",
        "import pydicom\n",
        "import dicom2nifti\n",
        "import SimpleITK as sitk\n",
        "import numpy as np\n",
        "import gzip\n",
        "import nibabel as nib\n",
        "from datetime import datetime\n",
        "\n",
        "\n",
        "\n",
        "# Flask app setup\n",
        "app = Flask(__name__)\n",
        "\n",
        "UPLOAD_FOLDER = 'uploads'\n",
        "PROCESSED_FOLDER = 'processed'\n",
        "NIFTI_FOLDER = 'nifti'\n",
        "os.makedirs(UPLOAD_FOLDER, exist_ok=True)\n",
        "os.makedirs(PROCESSED_FOLDER, exist_ok=True)\n",
        "os.makedirs(NIFTI_FOLDER, exist_ok=True)\n",
        "\n",
        "def is_dicom_file(file_path):\n",
        "    \"\"\"Check if a file is a valid DICOM file.\"\"\"\n",
        "    try:\n",
        "        pydicom.dcmread(file_path)\n",
        "        return True\n",
        "    except Exception:\n",
        "        return False\n",
        "def extract_and_convert_dicom_to_nifti(dicom_file_path, output_dir):\n",
        "    \"\"\"Convert a single DICOM file to NIfTI format.\"\"\"\n",
        "    try:\n",
        "        print(f\" Processing DICOM file: {dicom_file_path}\")\n",
        "\n",
        "        # Check if the uploaded file is a valid DICOM\n",
        "        if not is_dicom_file(dicom_file_path):\n",
        "            raise ValueError(f\"The file {dicom_file_path} is not a valid DICOM file.\")\n",
        "        #print(f\" Valid DICOM file detected: {dicom_file_path}\")\n",
        "\n",
        "        # Convert the DICOM file to NIfTI\n",
        "        nifti_file_name = os.path.join(\n",
        "            output_dir, os.path.basename(dicom_file_path).replace(\".dcm\", \"_0000.nii.gz\")\n",
        "        )\n",
        "        sitk_image = sitk.ReadImage(dicom_file_path)\n",
        "        sitk.WriteImage(sitk_image, nifti_file_name)\n",
        "        print(f\" DICOM converted to NIfTI: {nifti_file_name}\")\n",
        "\n",
        "        return nifti_file_name\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\" ERROR in extract_and_convert_dicom_to_nifti: {e}\")\n",
        "        raise\n",
        "\n",
        "def process_files(file_paths, output_dir):\n",
        "    \"\"\"Run nnUNetv2_predict for multiple files.\"\"\"\n",
        "    try:\n",
        "        #print(f\" Processing files: {file_paths}\")\n",
        "\n",
        "        os.environ[\"nnUNet_raw\"] = \"/content/drive/MyDrive/nnUNet_data/nnUNet_raw\"\n",
        "        os.environ[\"nnUNet_preprocessed\"] = \"/content/drive/MyDrive/nnUNet_data/preprocessed\"\n",
        "        os.environ[\"nnUNet_results\"] = \"/content/drive/MyDrive/nnUNet_data/nnUNet_results\"\n",
        "        print(\"Current Working Directory:\", os.getcwd())\n",
        "\n",
        "        command = [\n",
        "            \"nnUNetv2_predict\",\n",
        "            \"-i\", NIFTI_FOLDER,\n",
        "            \"-o\", output_dir,\n",
        "            \"-d\", \"Dataset206_brainsv2\",\n",
        "            \"-f\", \"0\", \"1\", \"2\", \"3\", \"4\",\n",
        "            \"-c\", \"3d_fullres\",\n",
        "            \"--disable_tta\"\n",
        "        ]\n",
        "        print(f\"🛠️ Running: {' '.join(command)}\")\n",
        "        result = subprocess.run(command, check=True, capture_output=True, text=True)\n",
        "        print(f\" nnUNet Output:\\n{result.stdout}\")\n",
        "\n",
        "        predicted_files = glob.glob(os.path.join(output_dir, \"*.nii.gz\"))\n",
        "        print(f\" Predicted files: {predicted_files}\")\n",
        "        return predicted_files if predicted_files else None\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\" ERROR in process_files: {e}\")\n",
        "        return None\n",
        "\n",
        "@app.route('/')\n",
        "def home():\n",
        "    return \"Flask Server is Running!\", 200\n",
        "\n",
        "@app.route('/predict', methods=['POST'])\n",
        "def predict():\n",
        "    try:\n",
        "        if 'files' not in request.files:\n",
        "            return jsonify({'status': 'error', 'message': 'No files uploaded'}), 400\n",
        "\n",
        "        files = request.files.getlist('files')\n",
        "        if not files or len(files) != 1:\n",
        "            return jsonify({'status': 'error', 'message': 'Please upload a single DICOM or NIfTI file'}), 400\n",
        "\n",
        "        file = files[0]\n",
        "        file_path = os.path.join(UPLOAD_FOLDER, file.filename)\n",
        "        file.save(file_path)\n",
        "\n",
        "        # Check file extension\n",
        "        if file.filename.endswith(\".dcm\"):\n",
        "            #print(f\" Processing DICOM file: {file.filename}\")\n",
        "            nifti_file = extract_and_convert_dicom_to_nifti(file_path, NIFTI_FOLDER)\n",
        "\n",
        "        elif file.filename.endswith(\".nii\") or file.filename.endswith(\".nii.gz\"):\n",
        "            #print(f\" NIfTI file detected: {file.filename}\")\n",
        "\n",
        "            if file.filename.endswith(\".nii\"):\n",
        "                try:\n",
        "                    compressed_file_path = os.path.join(NIFTI_FOLDER, file.filename + \".gz\")\n",
        "                    print(f\"🔄 Converting .nii to .nii.gz: {file_path} → {compressed_file_path}\")\n",
        "\n",
        "                    # Load the .nii file using nibabel\n",
        "                    nifti_image = nib.load(file_path)\n",
        "\n",
        "                    # Save it as .nii.gz\n",
        "                    nib.save(nifti_image, compressed_file_path)\n",
        "\n",
        "                    # Remove the original .nii file\n",
        "                    os.remove(file_path)\n",
        "\n",
        "                    # Update file_path to the new compressed file\n",
        "                    file_path = compressed_file_path\n",
        "                except Exception as e:\n",
        "                    print(f\"🔥 ERROR converting .nii to .nii.gz: {e}\")\n",
        "                    return jsonify({'status': 'error', 'message': 'Failed to convert .nii to .nii.gz'}), 500\n",
        "\n",
        "            # Debug the current file_path\n",
        "            print(f\"📂 Updated file path: {file_path}\")\n",
        "\n",
        "            # Ensure the filename ends with _0000 before moving\n",
        "            base_name, ext = os.path.splitext(file.filename)\n",
        "            if ext == \".gz\":  # For .nii.gz files, split twice\n",
        "                base_name, ext1 = os.path.splitext(base_name)\n",
        "                ext = ext1 + ext\n",
        "\n",
        "            if not base_name.endswith(\"_0000\"):\n",
        "                base_name += \"_0000\"\n",
        "\n",
        "            corrected_file_name = base_name + ext  # Preserve the correct .nii.gz extension\n",
        "            if not corrected_file_name.endswith(\".nii.gz\"):  # Safeguard against .nii errors\n",
        "                corrected_file_name += \".gz\"\n",
        "\n",
        "            nifti_file = os.path.join(NIFTI_FOLDER, corrected_file_name)\n",
        "            shutil.move(file_path, nifti_file)\n",
        "            #print(f\"✅ NIfTI file renamed and moved to: {nifti_file}\")\n",
        "\n",
        "\n",
        "\n",
        "        else:\n",
        "            return jsonify({'status': 'error', 'message': 'Unsupported file format. Only .dcm, .nii, and .nii.gz are supported.'}), 400\n",
        "\n",
        "        # Run predictions\n",
        "        predicted_files = process_files([nifti_file], PROCESSED_FOLDER)\n",
        "        if predicted_files:\n",
        "            segmented_files = [\n",
        "                {\n",
        "                    'name': os.path.basename(f),\n",
        "                    'url': f\"/processed/{os.path.basename(f)}\"\n",
        "                }\n",
        "                for f in predicted_files\n",
        "            ]\n",
        "            return jsonify({\n",
        "                'status': 'completed',\n",
        "                'message': f\"Processed {len(predicted_files)} files successfully.\",\n",
        "                'segmented_files': segmented_files\n",
        "            }), 200\n",
        "        else:\n",
        "            return jsonify({'status': 'error', 'message': 'Processing failed.'}), 500\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"🔥 ERROR in predict: {e}\")\n",
        "        return jsonify({'status': 'error', 'message': str(e)}), 500\n",
        "\n",
        "@app.route('/processed/<filename>', methods=['GET'])\n",
        "def serve_processed_file(filename):\n",
        "    return send_from_directory(PROCESSED_FOLDER, filename)\n",
        "\n",
        "\n",
        "@app.route('/download-all', methods=['POST'])\n",
        "def download_all():\n",
        "    try:\n",
        "        file_names = request.json.get(\"file_names\", [])\n",
        "        if not file_names:\n",
        "            return jsonify({\"status\": \"error\", \"message\": \"No files provided\"}), 400\n",
        "\n",
        "        # Check for missing files\n",
        "        missing_files = [name for name in file_names if not os.path.exists(os.path.join(PROCESSED_FOLDER, name))]\n",
        "        if missing_files:\n",
        "            return jsonify({\n",
        "                \"status\": \"error\",\n",
        "                \"message\": f\"Missing files: {', '.join(missing_files)}\"\n",
        "            }), 404\n",
        "\n",
        "        # Generate a timestamp for the ZIP file name\n",
        "        timestamp = datetime.now().strftime(\"%H%M%S\")\n",
        "        zip_file_name = f\"segmented_files_{timestamp}.zip\"\n",
        "        zip_file_path = os.path.join(PROCESSED_FOLDER, zip_file_name)\n",
        "\n",
        "        # Create the ZIP file\n",
        "        with zipfile.ZipFile(zip_file_path, 'w') as zf:\n",
        "            for file_name in file_names:\n",
        "                file_path = os.path.join(PROCESSED_FOLDER, file_name)\n",
        "                zf.write(file_path, arcname=os.path.basename(file_path))\n",
        "\n",
        "        # Return the download URL\n",
        "        return jsonify({\n",
        "            \"status\": \"success\",\n",
        "            \"message\": \"ZIP file created successfully\",\n",
        "            \"download_url\": f\"{request.host_url}processed/{zip_file_name}\"\n",
        "        })\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"🔥 ERROR in /download-all: {e}\")\n",
        "        return jsonify({\"status\": \"error\", \"message\": str(e)}), 500"
      ],
      "metadata": {
        "id": "mVBLYEtdpK3V"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# Start ngrok and get the public URL\n",
        "from pyngrok import ngrok\n",
        "auth_token = \"2plIUtXATOxsvN5a1n7L5QVixr6_w1p8apzWguD5aC6ZRinW\"\n",
        "ngrok.set_auth_token(auth_token)\n",
        "\n",
        "public_url = ngrok.connect(5000)\n",
        "print(f\"Public URL: {public_url}\")\n",
        "\n",
        "# to run flask on the same thread\n",
        "app.run(host=\"0.0.0.0\", port=5000, debug=False)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5m1GW4DMQPwB",
        "outputId": "6af240d0-2210-4179-a817-b2e26cc28702"
      },
      "execution_count": 3,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Public URL: NgrokTunnel: \"https://5c21-34-87-180-203.ngrok-free.app\" -> \"http://localhost:5000\"\n",
            " * Serving Flask app '__main__'\n",
            " * Debug mode: off\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:werkzeug:\u001b[31m\u001b[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\u001b[0m\n",
            " * Running on all addresses (0.0.0.0)\n",
            " * Running on http://127.0.0.1:5000\n",
            " * Running on http://172.28.0.12:5000\n",
            "INFO:werkzeug:\u001b[33mPress CTRL+C to quit\u001b[0m\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " Processing DICOM file: uploads/1.dcm\n",
            " DICOM converted to NIfTI: nifti/1_0000.nii.gz\n",
            "Current Working Directory: /content\n",
            "🛠️ Running: nnUNetv2_predict -i nifti -o processed -d Dataset206_brainsv2 -f 0 1 2 3 4 -c 3d_fullres --disable_tta\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:werkzeug:127.0.0.1 - - [03/Mar/2025 08:38:14] \"POST /predict HTTP/1.1\" 200 -\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " nnUNet Output:\n",
            "\n",
            "#######################################################################\n",
            "Please cite the following paper when using nnU-Net:\n",
            "Isensee, F., Jaeger, P. F., Kohl, S. A., Petersen, J., & Maier-Hein, K. H. (2021). nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation. Nature methods, 18(2), 203-211.\n",
            "#######################################################################\n",
            "\n",
            "There are 1 cases in the source folder\n",
            "I am process 0 out of 1 (max process ID is 0, we start counting with 0!)\n",
            "There are 1 cases that I would like to predict\n",
            "\n",
            "Predicting 1:\n",
            "perform_everything_on_device: True\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with 1\n",
            "\n",
            " Predicted files: ['processed/1.nii.gz']\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:werkzeug:127.0.0.1 - - [03/Mar/2025 08:38:14] \"POST /download-all HTTP/1.1\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [03/Mar/2025 08:50:18] \"GET /processed/segmented_files_083814.zip HTTP/1.1\" 200 -\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "HBSJwe4oQPyf"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n"
      ],
      "metadata": {
        "id": "SdDe87wIQP1c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "tuzKne37QP4A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ch5UODj77mp7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "LniFg2YCQCYM"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}